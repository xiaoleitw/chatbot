{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import choice\n",
    "import copy\n",
    "import random\n",
    "import re\n",
    "\n",
    "entity_path = \"../entity/\"\n",
    "csv_path = \"../csv/\"\n",
    "train_path = \"../train/\"\n",
    "intent_path = \"../intent/\"\n",
    "\n",
    "import csv\n",
    "\n",
    "def read_chinese():\n",
    "    reader = csv.reader(open(\"../raw-data/chinese.txt\", 'r', encoding='utf-8'), delimiter=\" \")\n",
    "    result = []\n",
    "    for i in reader:\n",
    "        result += i\n",
    "        \n",
    "    return result\n",
    "\n",
    "noise_lib = read_chinese()\n",
    "\n",
    "def read_csv(file, column):\n",
    "    reader = csv.reader(open(csv_path + file, 'r', encoding='utf-8'), delimiter=\"\\t\")\n",
    "    result = []\n",
    "    for i in reader:\n",
    "        result.append(i[column-1])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def load_json(path, file):\n",
    "    with open(path + file + \".json\", 'r', encoding='utf-8') as jsonfile:\n",
    "        return json.load(jsonfile)\n",
    "\n",
    "def load_entity(file):\n",
    "    return load_json(entity_path, file)\n",
    "\n",
    "def load_intent(file):\n",
    "    return load_json(intent_path, file)\n",
    "\n",
    "samples_dict = {}\n",
    "\n",
    "\n",
    "def find_entity(entities, obj_name):\n",
    "    for i in entities:\n",
    "        if i['entity'] == obj_name:\n",
    "            return i\n",
    "\n",
    "def handle_enum_type(entity):\n",
    "    e = entity['enum']\n",
    "    name = entity['entity']\n",
    "    if name not in samples_dict:\n",
    "        samples_dict[name] = read_csv(e['source'], e['column'])\n",
    "        \n",
    "    return entity, []\n",
    "        \n",
    "def handle_compound_type(js, entity):\n",
    "    children = []\n",
    "    for i in entity['compound']:\n",
    "        sample, tp = handle_entity(js, i['type'])\n",
    "        children.append((i['name'], sample, tp))\n",
    "        \n",
    "    return entity, children\n",
    "        \n",
    "def handle_choice_type(js, entity):\n",
    "    children = []\n",
    "    \n",
    "    for i in entity['choice']:\n",
    "        c = handle_entity(js, i)\n",
    "        children.append(c)\n",
    "        \n",
    "    return entity, children   \n",
    "\n",
    "def handle_templates_type(js, entity):\n",
    "    \n",
    "def handle_entity(js, c):\n",
    "    #print(c)\n",
    "    entity = find_entity(js, c)\n",
    "    if 'enum' in entity:\n",
    "        return handle_enum_type(entity)\n",
    "    elif 'compound' in entity:\n",
    "        return handle_compound_type(js, entity)\n",
    "    elif 'choice' in entity:\n",
    "        return handle_choice_type(js, entity)\n",
    "    elif 'templates' in entity:\n",
    "        return handle_templates_type(js, entity)\n",
    "    \n",
    "    print(\"ERROR\", entity)\n",
    "    return 0,0\n",
    "\n",
    "\n",
    "\n",
    "def get_generated_number_of_samples(total, n, allocated):\n",
    "    number = (n * allocated) // total\n",
    "    return max(10, number)\n",
    "\n",
    "def generate_enum_samples_by_pattern(patterns, samples, n_samples):\n",
    "    result = []\n",
    "    for p in patterns:\n",
    "        pos = p.find(\"@{this}\")\n",
    "        result += [((pos, len(s)), p.replace('@{this}', s)) for s in samples]\n",
    "        \n",
    "    random.shuffle(result)\n",
    "    \n",
    "    return result[:n_samples]\n",
    "    \n",
    "def flatten_generate_enum_samples(entity, n_samples):\n",
    "    name, samples, typ = generate_enum_samples(entity, n_samples)\n",
    "    return name, [s[1] for s in samples], typ\n",
    "        \n",
    "    \n",
    "def generate_enum_samples(entity, n_samples):\n",
    "    name = entity['entity']\n",
    "    samples = [choice(samples_dict[name]) for i in range(n_samples)]\n",
    "    \n",
    "    if \"patterns\" in entity:\n",
    "        samples = generate_enum_samples_by_pattern(entity['patterns'], samples, n_samples)\n",
    "    else:\n",
    "        samples = [((0, len(s)), s) for s in samples]\n",
    "        \n",
    "    return name, samples, 'enum'\n",
    "\n",
    "def split_pattern(pattern):\n",
    "    pos = pattern.find('@{')\n",
    "    if pos < 0:\n",
    "        return [pattern]\n",
    "    \n",
    "    end = pattern.find('}')\n",
    "    \n",
    "    result = []\n",
    "    if pos > 0:\n",
    "        result += [pattern[:pos]]\n",
    "        \n",
    "    result += [pattern[pos:end+1]]\n",
    "    \n",
    "    if end < len(pattern) - 1:\n",
    "        result += split_pattern(pattern[end+1:])\n",
    "    \n",
    "    return  result\n",
    "\n",
    "def get_pattern(pattern):\n",
    "    result = split_pattern(pattern)\n",
    "    \n",
    "    tags = {}\n",
    "    for s, i in zip(result, range(len(result))):\n",
    "        if s.startswith('@{'):\n",
    "            tags[s] = i\n",
    "    \n",
    "    return tags, result\n",
    "\n",
    "\n",
    "def get_pos(sample, index):\n",
    "    start = 0\n",
    "    for i in range(index):\n",
    "        start += len(sample[i])\n",
    "        \n",
    "    return start, len(sample[index])\n",
    "\n",
    "\n",
    "    \n",
    "def generate_compound_samples(entity, children, n_samples):\n",
    "    samples = []\n",
    "\n",
    "    for child in children:\n",
    "        name = child[0]\n",
    "        this_entity = child[1]\n",
    "        this_children = child[2]\n",
    "        if 'enum' in this_entity:\n",
    "            _, sample, tp = flatten_generate_enum_samples(this_entity, n_samples)\n",
    "            samples.append((name, sample, tp))\n",
    "        elif 'compound' in this_entity:\n",
    "            _, sample, tp = flatten_generate_compound_samples(this_entity, this_children, n_samples)\n",
    "            samples.append((name, sample, tp))\n",
    "        elif 'choice' in this_entity:\n",
    "            _, sample, tp = flatten_generate_choice_samples(this_entity, this_children, n_samples)\n",
    "            samples.append((name, sample, tp))\n",
    "    \n",
    "    #print(\"samples: \", samples, n_samples)\n",
    "    \n",
    "    #mandatory_dict = {}\n",
    "    #for ent in entity['compound']:\n",
    "        #print(ent)\n",
    "    #    mandatory_dict[ent['name']] = ent['mandatory']\n",
    "    \n",
    "    patterns = entity['patterns']\n",
    "    all_samples = []\n",
    "    #print(n_samples)\n",
    "    for p in patterns:\n",
    "        pattern = get_pattern(p)\n",
    "        #print(pattern)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            s = copy.deepcopy(pattern[1])\n",
    "            #print(s)\n",
    "            #record = {}\n",
    "            tags = copy.deepcopy(pattern[0])\n",
    "           \n",
    "            for sample_group in samples:\n",
    "                sample_group_data = sample_group[1]\n",
    "                tag = '@{' + sample_group[0] + '}'\n",
    "                \n",
    "                if tag in tags: \n",
    "                    #print(\"===: \", i, tags[tag])\n",
    "                    select_data = sample_group_data[i]\n",
    "                    #if (not mandatory_dict[sample_group[0]]) and choice([False, True]):\n",
    "                    #    select_data = \"\"\n",
    "                    \n",
    "                    s[tags[tag]] = select_data\n",
    "                \n",
    "            for k in tags:\n",
    "                tags[k] = get_pos(s, tags[k])\n",
    "            \n",
    "            #print(str(len(s)) + \" : \" + str(n_samples))\n",
    "            #print(\"ss: \", s, tags)\n",
    "            all_samples.append((tags, ''.join(s)))\n",
    "            \n",
    "    \n",
    "    random.shuffle(all_samples)\n",
    "    all_samples = all_samples[:n_samples]\n",
    "\n",
    "    #print(all_samples)\n",
    "    return entity['entity'], all_samples, 'compound'\n",
    "    \n",
    "def flatten_generate_compound_samples(entity, children, n_samples):\n",
    "    e, samples, _ = generate_compound_samples(entity, children, n_samples)\n",
    "    all_samples = [i[1] for i in samples]\n",
    "    random.shuffle(all_samples)\n",
    "    return entity['entity'], all_samples, 'enum'\n",
    "    \n",
    "def flatten_samples(entity, samples):\n",
    "    results = []\n",
    "    for s in samples:\n",
    "        #print(s)\n",
    "        typ = s[2]\n",
    "        if typ == 'compound':\n",
    "            results += [i[1] for i in s[1]]\n",
    "        elif typ == 'enum':\n",
    "            results += s[1]\n",
    "        else:\n",
    "            print(\"ERROR\")\n",
    "    \n",
    "    random.shuffle(results)\n",
    "    \n",
    "    return entity, results, 'enum'\n",
    "    \n",
    "def flatten_generate_choice_samples(entity, children, n_samples):\n",
    "    e, samples, _ = generate_choice_samples(entity, children, n_samples)\n",
    "    return flatten_samples(e, samples)\n",
    "            \n",
    "\n",
    "def generate_choice_samples(entity, children, n_samples):\n",
    "    all_samples = []\n",
    "    for i in sorted(children, key=lambda x: x[0]):\n",
    "        s = (n_samples // len(children)) + 1 #get_generated_number_of_samples(n, i[0], m)\n",
    "        \n",
    "        ent = i[1]\n",
    "        if 'enum' in ent:\n",
    "            r = flatten_generate_enum_samples(ent, s)\n",
    "        elif 'compound' in ent:\n",
    "            r = flatten_generate_compound_samples(ent, i[2], s)\n",
    "        elif 'choice' in ent:\n",
    "            r = flatten_generate_choice_samples(ent, i[2], s)\n",
    "        else:\n",
    "            r = None\n",
    "        \n",
    "        all_samples.append(r)\n",
    "        \n",
    "    random.shuffle(all_samples)\n",
    "\n",
    "    return entity['entity'], all_samples, 'choice'\n",
    "    \n",
    "\n",
    "def generate_sample(tree, n_samples):\n",
    "    entry = tree[1]\n",
    "    children = tree[2]\n",
    "    if 'choice' in entry:\n",
    "        return generate_choice_samples(entry, children, n_samples)\n",
    "    elif 'compound' in entry:\n",
    "        return generate_compound_samples(entry, children, n_samples)\n",
    "    elif 'enum' in entry:\n",
    "        return generate_enum_samples(entry, n_samples)\n",
    "    \n",
    "    print(\"ERROR\")\n",
    "    \n",
    "    return []\n",
    "\n",
    "def make_enum_label(samples, label):\n",
    "    result = []\n",
    "    for sample in samples:\n",
    "        s = []\n",
    "        for i in sample:\n",
    "            s.append([i, label])\n",
    "        result.append(s)\n",
    "        \n",
    "    return result\n",
    "\n",
    "def make_compound_label(samples, label):\n",
    "    result = []\n",
    "    for sample in samples:\n",
    "        s = []\n",
    "        for i in sample[1]:\n",
    "            s.append([i, label])\n",
    "        result.append(s)\n",
    "        \n",
    "    return result\n",
    "\n",
    "def generated_labeled_choice_sample(samples):\n",
    "    result = []\n",
    "    for i in range(len(samples)):\n",
    "        label = \"C\" + str(i)\n",
    "        ss = samples[i]\n",
    "        if ss[2] == 'enum':\n",
    "            result += make_enum_label(ss[1], label)\n",
    "        elif ss[2] == 'compound':\n",
    "            result += make_compound_label(ss[1], label)\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "def make_enum_test_data(samples):\n",
    "    result = []\n",
    "    for sample in samples:\n",
    "        s = []\n",
    "        for i in sample:\n",
    "            s.append([i])\n",
    "        s.append([\"。\"])\n",
    "        result.append(s)\n",
    "        \n",
    "    return result\n",
    "    \n",
    "def make_compound_test_label(samples):\n",
    "    result = []\n",
    "    for sample in samples:\n",
    "        s = []\n",
    "        for i in sample[1]:\n",
    "            s.append([i])\n",
    "        s.append([\"。\"])\n",
    "        result.append(s)\n",
    "        \n",
    "    return result\n",
    "    \n",
    "def generate_test_data(samples):\n",
    "    result = []\n",
    "    for i in range(len(samples)):\n",
    "        ss = samples[i]\n",
    "        if ss[2] == 'enum':\n",
    "            result += make_enum_test_data(ss[1])\n",
    "        elif ss[2] == 'compound':\n",
    "            result += make_compound_test_label(ss[1])\n",
    "            \n",
    "    return result\n",
    "\n",
    "range_tags = [\"A\", \"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]\n",
    "\n",
    "def generate_compound_labels(entity):\n",
    "    labels = {}\n",
    "    \n",
    "    print(entity)\n",
    "    elems = entity['compound']\n",
    "    \n",
    "    for n, i in zip(elems, range(len(elems))):\n",
    "        labels[n[\"name\"]] = range_tags[i]\n",
    "        \n",
    "    return labels\n",
    "\n",
    "def make_noise():\n",
    "    num = choice(range(1,5,1))\n",
    "    return [[choice(noise_lib), 'O'] for i in range(num)]\n",
    "\n",
    "def make_noised_sample(data, add_noice):\n",
    "    if add_noice:\n",
    "        return make_noise() + data + make_noise() + [['。', 'O']]\n",
    "    else:\n",
    "        return data + [['。', 'O']]\n",
    "    \n",
    "def label_compound_samples(entity, samples, add_noice):\n",
    "    results = []\n",
    "    \n",
    "    labels = generate_compound_labels(entity)\n",
    "    \n",
    "    #print(samples)\n",
    "    for i in samples:\n",
    "        label = i[0]\n",
    "        data = [[c, 'O'] for c in i[1]]\n",
    "\n",
    "        for tag in label:\n",
    "            begin, size = label[tag]\n",
    "            match = re.match( r'@\\{(.*)\\}', tag, re.M|re.I)\n",
    "            tag_name = match.group(1)\n",
    "            #print(\"---\", begin, size)\n",
    "            for k in range(begin, begin+size):\n",
    "                data[k][1] = labels[tag_name]\n",
    "                \n",
    "        results += make_noised_sample(data, add_noice)\n",
    "        \n",
    "    \n",
    "    #print(data)\n",
    "    return labels, results\n",
    "\n",
    "def label_choice_samples(samples, add_noice):\n",
    "    results = []\n",
    "    \n",
    "    labels = {}\n",
    "    #print(samples)\n",
    "    for s, i in zip(samples, range(len(samples))):\n",
    "        labels[s[0]] = range_tags[i]\n",
    "        for d in s[1]:\n",
    "            data = [[c, range_tags[i]] for c in d]\n",
    "            results += make_noised_sample(data, add_noice)\n",
    "    \n",
    "    return labels, results\n",
    "\n",
    "def do_write_csv_data(entity, samples, ty):\n",
    "    with open(train_path + entity + \"/\" + ty + '.data', 'w', encoding='utf-8') as csvfile:\n",
    "        my_writer = csv.writer(csvfile, delimiter='\\t',lineterminator='\\n')\n",
    "        for i in samples:\n",
    "            my_writer.writerow(i)\n",
    "            \n",
    "def do_write_training_data(entity, samples):\n",
    "    label_dict = samples[0]\n",
    "    labels = [[label_dict[l], l] for l in label_dict]\n",
    "    \n",
    "    do_write_csv_data(entity, labels, \"labels\")\n",
    "    do_write_csv_data(entity, samples[1], \"train\")\n",
    "\n",
    "def do_write_test_data(entity, samples):\n",
    "    do_write_csv_data(entity, samples, \"test\")\n",
    "\n",
    "        \n",
    "def write_training_data(js, samples, add_noise):\n",
    "    entity = samples[0]\n",
    "    typ = samples[2]\n",
    "    data = samples[1]\n",
    "    random.shuffle(data)\n",
    "\n",
    "    if typ == 'compound':\n",
    "        do_write_training_data(entity, label_compound_samples(find_entity(js, entity), data, add_noise))\n",
    "    elif typ == 'choice':\n",
    "        do_write_training_data(entity, label_choice_samples(data, add_noise))\n",
    "\n",
    "def make_samples(js, entity_name, num):\n",
    "    return generate_sample(handle_entity(js, entity_name), num)\n",
    "    \n",
    "def make_training_file(js, entity_name, num, add_noise):\n",
    "    write_training_data(js, make_samples(js, entity_name, num), add_noise)\n",
    "\n",
    "def make_compound_test_samples(samples):\n",
    "    results = []\n",
    "    #print(samples)\n",
    "    for i in samples:\n",
    "        results += i[1]\n",
    "        results.append(['。'])\n",
    "\n",
    "    return results\n",
    "\n",
    "def make_choice_test_samples(samples):\n",
    "    results = []\n",
    "    \n",
    "    for s in samples:\n",
    "        for d in s[1]:\n",
    "            results += [[c] for c in d]\n",
    "            results += [['。']]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def write_test_data(samples):\n",
    "    entity = samples[0]\n",
    "    typ = samples[2]\n",
    "    data = samples[1]\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    if typ == 'compound':\n",
    "        do_write_test_data(entity, make_compound_test_samples(data))\n",
    "    elif typ == 'choice':\n",
    "        do_write_test_data(entity, make_choice_test_samples(data))\n",
    "    elif typ == 'enum':\n",
    "        do_write_test_data(entity, make_enum_test_samples(data))\n",
    "\n",
    "def make_test_file(js, entity_name, num):\n",
    "    write_test_data(make_samples(js, entity_name, num))\n",
    "\n",
    "def make_entity_data(js, entity_name, train_n=100, test_n=10, add_noise=False):\n",
    "    make_training_file(js, entity_name, train_n, add_noise)\n",
    "    make_test_file(js, entity_name, test_n)\n",
    "    \n",
    "    \n",
    "js = load_entity('datetime') + load_entity('date') + load_entity('time') \n",
    "js += load_entity('city') + load_entity('ticket')\n",
    "js += load_intent('book-ticket')\n",
    "#result\n",
    "#get_pattern(\"从@{from}到@{end}sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('huge-muni-city',\n",
       " [((0, 2), '重庆市'),\n",
       "  ((0, 2), '重庆'),\n",
       "  ((0, 2), '重庆市'),\n",
       "  ((0, 2), '重庆'),\n",
       "  ((0, 2), '重庆'),\n",
       "  ((0, 2), '重庆市'),\n",
       "  ((0, 2), '重庆市'),\n",
       "  ((0, 2), '重庆市'),\n",
       "  ((0, 2), '重庆市'),\n",
       "  ((0, 2), '重庆')],\n",
       " 'enum')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_samples(js, 'huge-muni-city', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'datetime', 'compound': [{'name': 'date', 'type': 'date'}, {'name': 'time', 'type': 'time'}], 'patterns': ['@{date}@{time}']}\n"
     ]
    }
   ],
   "source": [
    "make_entity_data(js, \"datetime\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_entity_data(js, \"date\", 100, add_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_entity_data(js, \"time\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR {'entity': 'any-date', 'templates': ['single', 'range', 'centered-range', 'or-list', 'and-list'], 'parameter-type': 'date'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'int' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1624c9c237e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_entity_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"any-date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-b22f86536859>\u001b[0m in \u001b[0;36mmake_entity_data\u001b[0;34m(js, entity_name, train_n, test_n, add_noise)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_entity_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0mmake_training_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m     \u001b[0mmake_test_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-b22f86536859>\u001b[0m in \u001b[0;36mmake_training_file\u001b[0;34m(js, entity_name, num, add_noise)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_training_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     \u001b[0mwrite_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_compound_test_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-b22f86536859>\u001b[0m in \u001b[0;36mmake_samples\u001b[0;34m(js, entity_name, num)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgenerate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle_entity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_training_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-b22f86536859>\u001b[0m in \u001b[0;36mgenerate_sample\u001b[0;34m(tree, n_samples)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'choice'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgenerate_choice_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'compound'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'int' is not iterable"
     ]
    }
   ],
   "source": [
    "make_entity_data(js, \"any-date\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'regular-month', 'compound': [{'name': 'year', 'type': 'year', 'required': False}, {'name': 'month', 'type': 'month', 'required': True}], 'patterns': ['@{year}@{month}']}\n"
     ]
    }
   ],
   "source": [
    "make_entity_data(js, \"regular-month\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'regular-day', 'compound': [{'name': 'month', 'type': 'regular-month', 'required': False}, {'name': 'day', 'type': 'day'}], 'patterns': ['@{month}@{day}']}\n"
     ]
    }
   ],
   "source": [
    "make_entity_data(js, \"regular-day\", 1000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "make_entity_data(js, \"range-time\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'province-city', 'compound': [{'name': 'province', 'type': 'province', 'required': False}, {'name': 'city', 'type': 'city', 'required': True}], 'patterns': ['@{province}@{city}']}\n"
     ]
    }
   ],
   "source": [
    "make_entity_data(js, \"province-city\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_entity_data(js, \"general-city\", 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'book-ticket', 'class': 'intent', 'compound': [{'name': 'date', 'type': 'datetime', 'required': True, 'multiple': True, 'priority': 2, 'question': '您要订那天的票？'}, {'name': 'from', 'type': 'general-city', 'required': False}, {'name': 'to', 'type': 'general-city', 'required': True, 'priority': 1, 'question': '您要订到哪里的票？'}, {'name': 'ticket', 'type': 'ticket', 'required': True, 'priority': 0, 'question': '请问您要订什么票？'}], 'patterns': ['我想订@{date}@{from}到@{to}的@{ticket}', '订@{date}@{from}至@{to}的@{ticket}', '帮我看看@{date}从@{from}到@{to}的@{ticket}', '帮我订张@{date}@{from}到@{to}的@{ticket}', '查一下@{date}从@{from}至@{to}的@{ticket}', '查下@{date}到@{to}的@{ticket}', '问下@{date}去@{to}的@{ticket}', '看下@{date}去@{to}的@{ticket}', '看下有@{date}去@{to}的@{ticket}吗', '查下@{date}@{from}至@{to}的@{ticket}', '帮我看看到@{to}的@{ticket}', '帮我看看有没有@{date}去@{to}的@{ticket}', '帮我订张@{from}到@{to}的@{ticket}', '@{date}@{from}到@{to}的@{ticket}', '@{date}去@{to}的@{ticket}']}\n"
     ]
    }
   ],
   "source": [
    "make_entity_data(js, \"book-ticket\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single-time\n",
      "qualified-time\n",
      "usual-time\n",
      "exact-time\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('single-time',\n",
       " [('usual-time', ['十七点', '二十三点一刻左右', '十二点', '二十三点整'], 'enum'),\n",
       "  ('qualified-time',\n",
       "   ['早晨零点三十六分', '上午七点五十四分', '中午二点五十一分左右', '晚上七点四十三分'],\n",
       "   'enum'),\n",
       "  ('exact-time', ['七点三十五分', '十四点十四分', '二十四点零四分左右', '零点三十三分'], 'enum')],\n",
       " 'choice')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_samples(js, 'single-time', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'range-time', 'compound': [{'name': 'from', 'type': 'single-time', 'required': True}, {'name': 'to', 'type': 'single-time', 'required': True}], 'patterns': ['@{from}到@{to}', '从@{from}到@{to}', '@{from}至@{to}之间']}\n"
     ]
    }
   ],
   "source": [
    "make_entity_data(js, \"range-time\",1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
